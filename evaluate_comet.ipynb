{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate by COMET\n",
    "\n",
    "This notebook evaluates COMET scores of raw code-switched inputs (baseline 1) and monolingual translations (baseline 2), then calculates deltas that code-switching system translations achieve from these two baselines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q unbabel-comet==2.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from comet import download_model, load_from_checkpoint\n",
    "\n",
    "model_path = download_model(\"Unbabel/wmt22-comet-da\")\n",
    "comet_model = load_from_checkpoint(model_path)\n",
    "comet_model.to('cuda')\n",
    "comet_model.device # check that your comet model is on 'cuda'\n",
    "\n",
    "lang_codes=['ar', 'ca', 'cy', 'de', 'et', 'fa', 'id', 'lv', 'mn', 'sl', 'sv', 'ta', 'tr']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Baseline Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw Code-Switched Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "\n",
    "for lang_code in lang_codes:\n",
    "  print(f\"Processing {lang_code}\")\n",
    "\n",
    "  dataset = load_dataset('sophiayk/CoVoSwitch', f\"{lang_code}_en_combined\", split='test')\n",
    "\n",
    "  with open(f\"/content/drive/MyDrive/clean_nllb200_distilled_600M/{lang_code}/csw.txt\", \"r\") as f:\n",
    "    nllb_translations_csw = f.readlines()\n",
    "    nllb_translations_csw = list(map(lambda x: x.rstrip(), nllb_translations_csw))\n",
    "\n",
    "  with open(f\"/content/drive/MyDrive/clean_nllb200_distilled_600M/{lang_code}/reverse_csw.txt\", \"r\") as f:\n",
    "    nllb_translations_rcsw = f.readlines()\n",
    "    nllb_translations_rcsw = list(map(lambda x: x.rstrip(), nllb_translations_rcsw))\n",
    "\n",
    "  with open(f\"/content/drive/MyDrive/clean_m2m100_418M/{lang_code}/csw.txt\", \"r\") as f:\n",
    "    m2m_translations_csw = f.readlines()\n",
    "    m2m_translations_csw = list(map(lambda x: x.rstrip(), m2m_translations_csw))\n",
    "\n",
    "  with open(f\"/content/drive/MyDrive/clean_m2m100_418M/{lang_code}/reverse_csw.txt\", \"r\") as f:\n",
    "    m2m_translations_rcsw = f.readlines()\n",
    "    m2m_translations_rcsw = list(map(lambda x: x.rstrip(), m2m_translations_rcsw))\n",
    "\n",
    "  csw_data = []\n",
    "  rcsw_data = []\n",
    "\n",
    "\n",
    "  references_en=[]\n",
    "  references_X = []\n",
    "  references_csw = []\n",
    "\n",
    "  for i in range(len(dataset)):\n",
    "    row = dataset[i]['translation']\n",
    "    references_en.append(row['en'])\n",
    "    references_X.append(row[lang_code])\n",
    "    references_csw.append(row['csw'])\n",
    "\n",
    "  # Baseline\n",
    "  print(\"Baselines\")\n",
    "  for ref_csw, ref_en in zip(references_csw, references_en):\n",
    "    csw_data.append({\"src\": ref_csw, \"mt\": ref_csw, \"ref\": ref_en})\n",
    "\n",
    "  for ref_rcsw, ref_X in zip(references_csw, references_X):\n",
    "    rcsw_data.append({\"src\": ref_rcsw, \"mt\": ref_rcsw, \"ref\": ref_X})\n",
    "\n",
    "  model_output = comet_model.predict(csw_data, batch_size=8, gpus=1)[0] # fetches list of scores\n",
    "  baseline_csw_score = round(np.mean(model_output)*100, 1)\n",
    "  print(f\"CSW COMET Score: {baseline_csw_score}\")\n",
    "\n",
    "  model_output = comet_model.predict(rcsw_data, batch_size=8, gpus=1)[0] # fetches list of scores\n",
    "  baseline_rcsw_score = round(np.mean(model_output)*100, 1)\n",
    "  print(f\"RCSW COMET Score: {baseline_rcsw_score}\")\n",
    "\n",
    "  # M2M100\n",
    "\n",
    "  print(\"M2M100\")\n",
    "\n",
    "  m2m_csw_data = []\n",
    "  m2m_rcsw_data = []\n",
    "\n",
    "  # X + en -> en\n",
    "  for ref_csw, trans_csw, ref_en in zip(ref_csw, m2m_translations_csw, references_en):\n",
    "    m2m_csw_data.append({\"src\": ref_csw, \"mt\": trans_csw, \"ref\": ref_en})\n",
    "\n",
    "  # X + en -> X\n",
    "  for csw, trans_rcsw, ref_X in zip(ref_csw, m2m_translations_rcsw, references_X):\n",
    "    m2m_rcsw_data.append({\"src\": ref_csw, \"mt\": trans_rcsw, \"ref\": ref_X})\n",
    "\n",
    "  model_output = comet_model.predict(m2m_csw_data, batch_size=8, gpus=1)[0] # fetches list of scores\n",
    "  score = round(np.mean(model_output)*100, 1)\n",
    "  print(f\"M2M CSW COMET Delta: {round(score-baseline_csw_score,1)}\")\n",
    "\n",
    "  model_output = comet_model.predict(m2m_rcsw_data, batch_size=8, gpus=1)[0] # fetches list of scores\n",
    "  score = round(np.mean(model_output)*100, 1)\n",
    "  print(f\"M2M RCSW COMET Delta: {round(score-baseline_rcsw_score,1)}\")\n",
    "\n",
    "  # NLLB200\n",
    "  print(\"NLLB200\")\n",
    "\n",
    "  nllb_csw_data = []\n",
    "  nllb_rcsw_data = []\n",
    "\n",
    "  # X + en -> en\n",
    "  for ref_csw, trans_csw, ref_en in zip(ref_csw, nllb_translations_csw, references_en):\n",
    "    nllb_csw_data.append({\"src\": ref_csw, \"mt\": trans_csw, \"ref\": ref_en})\n",
    "\n",
    "  # X + en -> X\n",
    "  for csw, trans_rcsw, ref_X in zip(ref_csw, nllb_translations_rcsw, references_X):\n",
    "    nllb_rcsw_data.append({\"src\": ref_csw, \"mt\": trans_rcsw, \"ref\": ref_X})\n",
    "\n",
    "  model_output = comet_model.predict(nllb_csw_data, batch_size=8, gpus=1)[0] # fetches list of scores\n",
    "  score = round(np.mean(model_output)*100, 1)\n",
    "  print(f\"NLLB CSW COMET Delta: {round(score-baseline_csw_score,1)}\")\n",
    "\n",
    "  model_output = comet_model.predict(nllb_rcsw_data, batch_size=8, gpus=1)[0] # fetches list of scores\n",
    "  score = round(np.mean(model_output)*100, 1)\n",
    "  print(f\"NLLB RCSW COMET Delta: {round(score-baseline_rcsw_score,1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monolingual Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# monolingual\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "\n",
    "for lang_code in lang_codes:\n",
    "  print(f\"Processing {lang_code}\")\n",
    "\n",
    "  dataset = load_dataset('sophiayk/CoVoSwitch', f\"{lang_code}_en_combined\", split='test')\n",
    "\n",
    "  with open(f\"/content/drive/MyDrive/clean_nllb200_distilled_600M/{lang_code}/monolingual.txt\", \"r\") as f:\n",
    "    nllb_trans_mono = f.readlines()\n",
    "    nllb_trans_mono= list(map(lambda x: x.rstrip(), nllb_trans_mono))\n",
    "\n",
    "  with open(f\"/content/drive/MyDrive/clean_nllb200_distilled_600M/{lang_code}/reverse_monolingual.txt\", \"r\") as f:\n",
    "    nllb_trans_rmono = f.readlines()\n",
    "    nllb_trans_rmono = list(map(lambda x: x.rstrip(), nllb_trans_rmono))\n",
    "\n",
    "  with open(f\"/content/drive/MyDrive/clean_m2m100_418M/{lang_code}/monolingual.txt\", \"r\") as f:\n",
    "    m2m_trans_mono = f.readlines()\n",
    "    m2m_trans_mono = list(map(lambda x: x.rstrip(), m2m_trans_mono))\n",
    "\n",
    "  with open(f\"/content/drive/MyDrive/clean_m2m100_418M/{lang_code}/reverse_monolingual.txt\", \"r\") as f:\n",
    "    m2m_trans_rmono = f.readlines()\n",
    "    m2m_trans_rmono = list(map(lambda x: x.rstrip(), m2m_trans_rmono))\n",
    "\n",
    "  csw_data = []\n",
    "  rcsw_data = []\n",
    "\n",
    "  references_en=[]\n",
    "  references_X = []\n",
    "  references_csw = []\n",
    "\n",
    "  for i in range(len(dataset)):\n",
    "    row = dataset[i]['translation']\n",
    "    references_en.append(row['en'])\n",
    "    references_X.append(row[lang_code])\n",
    "    references_csw.append(row['csw'])\n",
    "\n",
    "  # Baseline\n",
    "  print(\"Baselines\")\n",
    "  for ref_csw, ref_en in zip(references_csw, references_en):\n",
    "    csw_data.append({\"src\": ref_csw, \"mt\": ref_csw, \"ref\": ref_en})\n",
    "\n",
    "  for ref_rcsw, ref_X in zip(references_csw, references_X):\n",
    "    rcsw_data.append({\"src\": ref_rcsw, \"mt\": ref_rcsw, \"ref\": ref_X})\n",
    "\n",
    "  model_output = comet_model.predict(csw_data, batch_size=8, gpus=1)[0] # fetches list of scores\n",
    "  baseline_csw_score = round(np.mean(model_output)*100, 1)\n",
    "  print(f\"CSW COMET Baseline Score: {baseline_csw_score}\")\n",
    "\n",
    "  model_output = comet_model.predict(rcsw_data, batch_size=8, gpus=1)[0] # fetches list of scores\n",
    "  baseline_rcsw_score = round(np.mean(model_output)*100, 1)\n",
    "  print(f\"RCSW COMET Baseline Score: {baseline_rcsw_score}\")\n",
    "\n",
    "  # M2M100\n",
    "\n",
    "  print(\"M2M100\")\n",
    "\n",
    "  m2m_csw_data = []\n",
    "  m2m_rcsw_data = []\n",
    "\n",
    "  # X + en -> en\n",
    "  for ref_csw, trans_mono, ref_en in zip(ref_csw, m2m_trans_mono, references_en):\n",
    "    m2m_csw_data.append({\"src\": ref_csw, \"mt\": trans_mono, \"ref\": ref_en})\n",
    "\n",
    "  # X + en -> X\n",
    "  for csw, trans_rmono, ref_X in zip(ref_csw, m2m_trans_rmono, references_X):\n",
    "    m2m_rcsw_data.append({\"src\": ref_csw, \"mt\": trans_rmono, \"ref\": ref_X})\n",
    "\n",
    "  model_output = comet_model.predict(m2m_csw_data, batch_size=8, gpus=1)[0] # fetches list of scores\n",
    "  score = round(np.mean(model_output)*100, 1)\n",
    "  print(f\"M2M CSW COMET X + en -> en score: {round(score,1)}\")\n",
    "\n",
    "  model_output = comet_model.predict(m2m_rcsw_data, batch_size=8, gpus=1)[0] # fetches list of scores\n",
    "  score = round(np.mean(model_output)*100, 1)\n",
    "  print(f\"M2M RCSW COMET X + en -> X score: {round(score, 1)}\")\n",
    "\n",
    "  # NLLB200\n",
    "  print(\"NLLB200\")\n",
    "\n",
    "  nllb_csw_data = []\n",
    "  nllb_rcsw_data = []\n",
    "\n",
    "  # X + en -> en\n",
    "  for ref_csw, trans_mono, ref_en in zip(ref_csw, nllb_trans_mono, references_en):\n",
    "    nllb_csw_data.append({\"src\": ref_csw, \"mt\": trans_mono, \"ref\": ref_en})\n",
    "\n",
    "  # X + en -> X\n",
    "  for csw, trans_rmono, ref_X in zip(ref_csw, nllb_trans_rmono, references_X):\n",
    "    nllb_rcsw_data.append({\"src\": ref_csw, \"mt\": trans_rmono, \"ref\": ref_X})\n",
    "\n",
    "  model_output = comet_model.predict(nllb_csw_data, batch_size=8, gpus=1)[0] # fetches list of scores\n",
    "  score = round(np.mean(model_output)*100, 1)\n",
    "  print(f\"NLLB CSW COMET X + en -> en: {round(score, 1)}\")\n",
    "\n",
    "  model_output = comet_model.predict(nllb_rcsw_data, batch_size=8, gpus=1)[0] # fetches list of scores\n",
    "  score = round(np.mean(model_output)*100, 1)\n",
    "  print(f\"NLLB RCSW COMET X + en -> X: {round(score, 1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comet Deltas, Relative to Monolingual Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "\n",
    "for lang_code in lang_codes[::-1]:\n",
    "  print(f\"Processing {lang_code}\")\n",
    "\n",
    "  dataset = load_dataset('sophiayk/CoVoSwitch', f\"{lang_code}_en_combined\", split='test')\n",
    "\n",
    "  # FETCH MONOLINGUAL\n",
    "  with open(f\"/content/drive/MyDrive/clean_nllb200_distilled_600M/{lang_code}/monolingual.txt\", \"r\") as f:\n",
    "    nllb_translations_mono = f.readlines()\n",
    "    nllb_translations_mono = list(map(lambda x: x.rstrip(), nllb_translations_mono))\n",
    "\n",
    "  with open(f\"/content/drive/MyDrive/clean_nllb200_distilled_600M/{lang_code}/reverse_monolingual.txt\", \"r\") as f:\n",
    "    nllb_translations_rmono = f.readlines()\n",
    "    nllb_translations_rmono = list(map(lambda x: x.rstrip(), nllb_translations_rmono))\n",
    "\n",
    "  with open(f\"/content/drive/MyDrive/clean_m2m100_418M/{lang_code}/monolingual.txt\", \"r\") as f:\n",
    "    m2m_translations_mono = f.readlines()\n",
    "    m2m_translations_mono = list(map(lambda x: x.rstrip(), m2m_translations_mono))\n",
    "\n",
    "  with open(f\"/content/drive/MyDrive/clean_m2m100_418M/{lang_code}/reverse_monolingual.txt\", \"r\") as f:\n",
    "    m2m_translations_rmono = f.readlines()\n",
    "    m2m_translations_rmono = list(map(lambda x: x.rstrip(), m2m_translations_rmono))\n",
    "\n",
    "  # FETCH CODE-SWITCHING\n",
    "  with open(f\"/content/drive/MyDrive/clean_nllb200_distilled_600M/{lang_code}/csw.txt\", \"r\") as f:\n",
    "    nllb_translations_csw = f.readlines()\n",
    "    nllb_translations_csw = list(map(lambda x: x.rstrip(), nllb_translations_csw))\n",
    "\n",
    "  with open(f\"/content/drive/MyDrive/clean_nllb200_distilled_600M/{lang_code}/reverse_csw.txt\", \"r\") as f:\n",
    "    nllb_translations_rcsw = f.readlines()\n",
    "    nllb_translations_rcsw = list(map(lambda x: x.rstrip(), nllb_translations_rcsw))\n",
    "\n",
    "  with open(f\"/content/drive/MyDrive/clean_m2m100_418M/{lang_code}/csw.txt\", \"r\") as f:\n",
    "    m2m_translations_csw = f.readlines()\n",
    "    m2m_translations_csw = list(map(lambda x: x.rstrip(), m2m_translations_csw))\n",
    "\n",
    "  with open(f\"/content/drive/MyDrive/clean_m2m100_418M/{lang_code}/reverse_csw.txt\", \"r\") as f:\n",
    "    m2m_translations_rcsw = f.readlines()\n",
    "    m2m_translations_rcsw = list(map(lambda x: x.rstrip(), m2m_translations_rcsw))\n",
    "\n",
    "  nllb_mono_data = []\n",
    "  nllb_rmono_data = []\n",
    "\n",
    "  m2m_mono_data = []\n",
    "  m2m_rmono_data = []\n",
    "\n",
    "  references_en=[]\n",
    "  references_X = []\n",
    "  references_csw = []\n",
    "\n",
    "  for i in range(len(dataset)):\n",
    "    row = dataset[i]['translation']\n",
    "    references_en.append(row['en'])\n",
    "    references_X.append(row[lang_code])\n",
    "    references_csw.append(row['csw'])\n",
    "\n",
    "  # Baseline\n",
    "  print(\"Baselines\")\n",
    "  # M2M X -> en\n",
    "  for ref_x, trans_mono, ref_en in zip(references_X, m2m_translations_mono, references_en):\n",
    "    m2m_mono_data.append({\"src\": ref_x, \"mt\": trans_mono, \"ref\": ref_en})\n",
    "\n",
    "  # M2M en -> X\n",
    "  for ref_en, trans_rmono, ref_X in zip(references_en, m2m_translations_rmono, references_X):\n",
    "    m2m_rmono_data.append({\"src\": ref_en, \"mt\": trans_rmono, \"ref\": ref_X})\n",
    "\n",
    "  # NLLB X -> en\n",
    "  for ref_x, trans_mono, ref_en in zip(references_X, nllb_translations_mono, references_en):\n",
    "    nllb_mono_data.append({\"src\": ref_x, \"mt\": trans_mono, \"ref\": ref_en})\n",
    "\n",
    "  # NLLB en -> X\n",
    "  for ref_en, trans_rmono, ref_X in zip(references_en, nllb_translations_rmono, references_X):\n",
    "    nllb_rmono_data.append({\"src\": ref_en, \"mt\": trans_rmono, \"ref\": ref_X})\n",
    "\n",
    "\n",
    "  print(\"M2M\")\n",
    "\n",
    "  model_output = comet_model.predict(m2m_mono_data, batch_size=8, gpus=1)[0] # fetches list of scores\n",
    "  m2m_baseline_mono_score = round(np.mean(model_output)*100, 1)\n",
    "  print(f\"BASELINE MONO COMET Score: {m2m_baseline_mono_score}\")\n",
    "\n",
    "  model_output = comet_model.predict(m2m_rmono_data, batch_size=8, gpus=1)[0] # fetches list of scores\n",
    "  m2m_baseline_rmono_score = round(np.mean(model_output)*100, 1)\n",
    "  print(f\"BASELINE RMONO COMET Score: {m2m_baseline_rmono_score}\")\n",
    "\n",
    "\n",
    "  print(\"NLLB\")\n",
    "\n",
    "  model_output = comet_model.predict(nllb_mono_data, batch_size=8, gpus=1)[0] # fetches list of scores\n",
    "  nllb_baseline_mono_score = round(np.mean(model_output)*100, 1)\n",
    "  print(f\"BASELINE MONO COMET Score: {nllb_baseline_mono_score}\")\n",
    "\n",
    "  model_output = comet_model.predict(nllb_rmono_data, batch_size=8, gpus=1)[0] # fetches list of scores\n",
    "  nllb_baseline_rmono_score = round(np.mean(model_output)*100, 1)\n",
    "  print(f\"BASELINE RMONO COMET Score: {nllb_baseline_rmono_score}\")\n",
    "\n",
    "  # M2M100\n",
    "\n",
    "  print(\"M2M100\")\n",
    "\n",
    "  m2m_csw_data = []\n",
    "  m2m_rcsw_data = []\n",
    "\n",
    "  # X + en -> en\n",
    "  for ref_csw, trans_csw, ref_en in zip(references_csw, m2m_translations_csw, references_en):\n",
    "    m2m_csw_data.append({\"src\": ref_csw, \"mt\": trans_csw, \"ref\": ref_en})\n",
    "\n",
    "  # X + en -> X\n",
    "  for ref_csw, trans_rcsw, ref_X in zip(references_csw, m2m_translations_rcsw, references_X):\n",
    "    m2m_rcsw_data.append({\"src\": ref_csw, \"mt\": trans_rcsw, \"ref\": ref_X})\n",
    "\n",
    "  model_output = comet_model.predict(m2m_csw_data, batch_size=8, gpus=1)[0] # fetches list of scores\n",
    "  score = round(np.mean(model_output)*100, 1)\n",
    "  print(f\"M2M CSW COMET Delta: {round(score-m2m_baseline_mono_score,1)}\")\n",
    "\n",
    "  model_output = comet_model.predict(m2m_rcsw_data, batch_size=8, gpus=1)[0] # fetches list of scores\n",
    "  score = round(np.mean(model_output)*100, 1)\n",
    "  print(f\"M2M RCSW COMET Delta: {round(score-m2m_baseline_rmono_score,1)}\")\n",
    "\n",
    "  # NLLB200\n",
    "  print(\"NLLB200\")\n",
    "\n",
    "  nllb_csw_data = []\n",
    "  nllb_rcsw_data = []\n",
    "\n",
    "  # X + en -> en\n",
    "  for ref_csw, trans_csw, ref_en in zip(references_csw, nllb_translations_csw, references_en):\n",
    "    nllb_csw_data.append({\"src\": ref_csw, \"mt\": trans_csw, \"ref\": ref_en})\n",
    "\n",
    "  # X + en -> X\n",
    "  for ref_csw, trans_rcsw, ref_X in zip(references_csw, nllb_translations_rcsw, references_X):\n",
    "    nllb_rcsw_data.append({\"src\": ref_csw, \"mt\": trans_rcsw, \"ref\": ref_X})\n",
    "\n",
    "  model_output = comet_model.predict(nllb_csw_data, batch_size=8, gpus=1)[0] # fetches list of scores\n",
    "  score = round(np.mean(model_output)*100, 1)\n",
    "  print(f\"NLLB CSW COMET Delta: {round(score-nllb_baseline_mono_score,1)}\")\n",
    "\n",
    "  model_output = comet_model.predict(nllb_rcsw_data, batch_size=8, gpus=1)[0] # fetches list of scores\n",
    "  score = round(np.mean(model_output)*100, 1)\n",
    "  print(f\"NLLB RCSW COMET Delta: {round(score-nllb_baseline_rmono_score,1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comet Deltas Relative to Raw Code-Switched Input Baselins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "\n",
    "for lang_code in lang_codes:\n",
    "  print(f\"Processing {lang_code}\")\n",
    "\n",
    "  dataset = load_dataset('sophiayk/CoVoSwitch', f\"{lang_code}_en_combined\", split='test')\n",
    "\n",
    "  # FETCH MONOLINGUAL\n",
    "  with open(f\"/content/drive/MyDrive/clean_nllb200_distilled_600M/{lang_code}/monolingual.txt\", \"r\") as f:\n",
    "    nllb_translations_mono = f.readlines()\n",
    "    nllb_translations_mono = list(map(lambda x: x.rstrip(), nllb_translations_mono))\n",
    "\n",
    "  with open(f\"/content/drive/MyDrive/clean_nllb200_distilled_600M/{lang_code}/reverse_monolingual.txt\", \"r\") as f:\n",
    "    nllb_translations_rmono = f.readlines()\n",
    "    nllb_translations_rmono = list(map(lambda x: x.rstrip(), nllb_translations_rmono))\n",
    "\n",
    "  with open(f\"/content/drive/MyDrive/clean_m2m100_418M/{lang_code}/monolingual.txt\", \"r\") as f:\n",
    "    m2m_translations_mono = f.readlines()\n",
    "    m2m_translations_mono = list(map(lambda x: x.rstrip(), m2m_translations_mono))\n",
    "\n",
    "  with open(f\"/content/drive/MyDrive/clean_m2m100_418M/{lang_code}/reverse_monolingual.txt\", \"r\") as f:\n",
    "    m2m_translations_rmono = f.readlines()\n",
    "    m2m_translations_rmono = list(map(lambda x: x.rstrip(), m2m_translations_rmono))\n",
    "\n",
    "  # FETCH CODE-SWITCHING\n",
    "  with open(f\"/content/drive/MyDrive/clean_nllb200_distilled_600M/{lang_code}/csw.txt\", \"r\") as f:\n",
    "    nllb_translations_csw = f.readlines()\n",
    "    nllb_translations_csw = list(map(lambda x: x.rstrip(), nllb_translations_csw))\n",
    "\n",
    "  with open(f\"/content/drive/MyDrive/clean_nllb200_distilled_600M/{lang_code}/reverse_csw.txt\", \"r\") as f:\n",
    "    nllb_translations_rcsw = f.readlines()\n",
    "    nllb_translations_rcsw = list(map(lambda x: x.rstrip(), nllb_translations_rcsw))\n",
    "\n",
    "  with open(f\"/content/drive/MyDrive/clean_m2m100_418M/{lang_code}/csw.txt\", \"r\") as f:\n",
    "    m2m_translations_csw = f.readlines()\n",
    "    m2m_translations_csw = list(map(lambda x: x.rstrip(), m2m_translations_csw))\n",
    "\n",
    "  with open(f\"/content/drive/MyDrive/clean_m2m100_418M/{lang_code}/reverse_csw.txt\", \"r\") as f:\n",
    "    m2m_translations_rcsw = f.readlines()\n",
    "    m2m_translations_rcsw = list(map(lambda x: x.rstrip(), m2m_translations_rcsw))\n",
    "\n",
    "  nllb_mono_data = []\n",
    "  nllb_rmono_data = []\n",
    "\n",
    "  m2m_mono_data = []\n",
    "  m2m_rmono_data = []\n",
    "\n",
    "  csw_data = []\n",
    "  rcsw_data = []\n",
    "\n",
    "  references_en=[]\n",
    "  references_X = []\n",
    "  references_csw = []\n",
    "\n",
    "  for i in range(len(dataset)):\n",
    "    row = dataset[i]['translation']\n",
    "    references_en.append(row['en'])\n",
    "    references_X.append(row[lang_code])\n",
    "    references_csw.append(row['csw'])\n",
    "\n",
    "  # Baseline\n",
    "  print(\"Baselines\")\n",
    "  # CSW, en\n",
    "  for ref_csw, ref_en in zip(references_csw, references_en):\n",
    "    csw_data.append({\"src\": ref_csw, \"mt\": ref_csw, \"ref\": ref_en})\n",
    "\n",
    "  # CSW, X\n",
    "  for ref_csw, ref_X in zip(references_csw, references_X):\n",
    "    rcsw_data.append({\"src\": ref_csw, \"mt\": ref_csw, \"ref\": ref_X})\n",
    "\n",
    "  print(\"M2M\")\n",
    "\n",
    "  model_output = comet_model.predict(csw_data, batch_size=8, gpus=1)[0]\n",
    "  baseline_csw_score = round(np.mean(model_output)*100, 1)\n",
    "  print(f\"Baseline CSW COMET Score: {baseline_csw_score}\")\n",
    "\n",
    "  model_output = comet_model.predict(rcsw_data, batch_size=8, gpus=1)[0]\n",
    "  baseline_rcsw_score = round(np.mean(model_output)*100, 1)\n",
    "  print(f\"Baseline RCSW COMET Score: {baseline_rcsw_score}\")\n",
    "\n",
    "  #M2M100\n",
    "  print(\"M2M100\")\n",
    "\n",
    "  m2m_csw_data = []\n",
    "  m2m_rcsw_data = []\n",
    "\n",
    "  # X + en -> en\n",
    "  for ref_csw, trans_csw, ref_en in zip(references_csw, m2m_translations_csw, references_en):\n",
    "    m2m_csw_data.append({\"src\": ref_csw, \"mt\": trans_csw, \"ref\": ref_en})\n",
    "\n",
    "  # X + en -> X\n",
    "  for ref_csw, trans_rcsw, ref_X in zip(references_csw, m2m_translations_rcsw, references_X):\n",
    "    m2m_rcsw_data.append({\"src\": ref_csw, \"mt\": trans_rcsw, \"ref\": ref_X})\n",
    "\n",
    "  model_output = comet_model.predict(m2m_csw_data, batch_size=8, gpus=1)[0] # fetches list of scores\n",
    "  score = round(np.mean(model_output)*100, 1)\n",
    "  print(f\"M2M CSW COMET Delta: {round(score-baseline_csw_score,1)}\")\n",
    "\n",
    "  model_output = comet_model.predict(m2m_rcsw_data, batch_size=8, gpus=1)[0] # fetches list of scores\n",
    "  score = round(np.mean(model_output)*100, 1)\n",
    "  print(f\"M2M RCSW COMET Delta: {round(score-baseline_rcsw_score,1)}\")\n",
    "\n",
    "  # NLLB200\n",
    "  print(\"NLLB200\")\n",
    "\n",
    "  nllb_csw_data = []\n",
    "  nllb_rcsw_data = []\n",
    "\n",
    "  # X + en -> en\n",
    "  for ref_csw, trans_csw, ref_en in zip(references_csw, nllb_translations_csw, references_en):\n",
    "    nllb_csw_data.append({\"src\": ref_csw, \"mt\": trans_csw, \"ref\": ref_en})\n",
    "\n",
    "  # X + en -> X\n",
    "  for ref_csw, trans_rcsw, ref_X in zip(references_csw, nllb_translations_rcsw, references_X):\n",
    "    nllb_rcsw_data.append({\"src\": ref_csw, \"mt\": trans_rcsw, \"ref\": ref_X})\n",
    "\n",
    "  model_output = comet_model.predict(nllb_csw_data, batch_size=8, gpus=1)[0] # fetches list of scores\n",
    "  score = round(np.mean(model_output)*100, 1)\n",
    "  print(f\"NLLB CSW COMET Delta: {round(score-baseline_csw_score,1)}\")\n",
    "\n",
    "  model_output = comet_model.predict(nllb_rcsw_data, batch_size=8, gpus=1)[0] # fetches list of scores\n",
    "  score = round(np.mean(model_output)*100, 1)\n",
    "  print(f\"NLLB RCSW COMET Delta: {round(score-baseline_rcsw_score,1)}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
